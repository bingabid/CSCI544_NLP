{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training, dev and unlabeled test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following provides a starting code (Python 3) of how to read the labeled training and dev cipher text, and unlabeled test cipher text, into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "16220\n"
    }
   ],
   "source": [
    "for x in open('./train_enc.tsv', encoding='utf-8'):\n",
    "    x = x.rstrip('\\n\\r').split('\\t')\n",
    "    # x[0] will be the label (0 or 1), and x[1] will be the ciphertext sentence.\n",
    "    x[0] = int(x[0]) \n",
    "    train.append(x)\n",
    "print (len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2027\n"
    }
   ],
   "source": [
    "for x in open('./dev_enc.tsv', encoding='utf-8'):\n",
    "    x = x.rstrip('\\n\\r').split('\\t')\n",
    "    # x[0] will be the label (0 or 1), and x[1] will be the ciphertext sentence.\n",
    "    x[0] = int(x[0]) \n",
    "    dev.append(x)\n",
    "print (len(dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different from 'train' and 'dev' that are both list of tuples, 'test' will be just a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2028\n"
    }
   ],
   "source": [
    "for x in open('./test_enc_unlabeled.tsv', encoding='utf-8'):\n",
    "    x = x.rstrip('\\n\\r')\n",
    "    test.append(x)\n",
    "print (len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can split every sentence into lists of words by white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main Code Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = [[x[0], x[1].split(' ')] for x in train]\n",
    "dev_split = [[x[0], x[1].split(' ')] for x in dev]\n",
    "test_split = [[x.split(' ')] for x in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "16220\n"
    }
   ],
   "source": [
    "train_sentences = [item[1] for item in train]\n",
    "y_train = [item[0] for item in train]\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2027\n"
    }
   ],
   "source": [
    "dev_sentences = [item[1] for item in dev]\n",
    "y_dev = [item[0] for item in dev]\n",
    "print(len(y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "5631\n"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer(min_df = 5, max_df = 0.90)\n",
    "X_train = tfidfconverter.fit_transform(train_sentences).toarray()\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "5631\n"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer(vocabulary=tfidfconverter.vocabulary_, min_df = 5, max_df = 0.90)\n",
    "X_dev = tfidfconverter.fit_transform(dev_sentences).toarray()\n",
    "print(len(X_dev[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "AdaBoostClassifier(algorithm='SAMME',\n                   base_estimator=Perceptron(alpha=1e-05, max_iter=10000,\n                                             penalty='l2', tol=1e-05),\n                   learning_rate=0.1, n_estimators=20000)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "base_perceptron = Perceptron(penalty = 'l2', alpha = 0.00001, tol = 1e-5, max_iter = 10000)\n",
    "perceptron_adaBoost = AdaBoostClassifier(base_estimator = base_perceptron, n_estimators = 20000, learning_rate = 0.1, algorithm='SAMME')\n",
    "perceptron_adaBoost.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[808 144]\n [153 922]]\n              precision    recall  f1-score   support\n\n           0       0.84      0.85      0.84       952\n           1       0.86      0.86      0.86      1075\n\n    accuracy                           0.85      2027\n   macro avg       0.85      0.85      0.85      2027\nweighted avg       0.85      0.85      0.85      2027\n\n0.8534780463739516\n"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "y_pred_ab_perceptron = perceptron_adaBoost.predict(X_dev)\n",
    "print(confusion_matrix(y_dev,y_pred_ab_perceptron))\n",
    "print(classification_report(y_dev,y_pred_ab_perceptron))\n",
    "print(accuracy_score(y_dev, y_pred_ab_perceptron))\n",
    "with open('adaboost_perceptron.txt', 'w') as wf:\n",
    "    for item in y_pred_ab_perceptron:\n",
    "        wf.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='rbf', tol=1e-6)\n",
    "svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "y_pred_svm = svm.predict(X_dev)\n",
    "print(confusion_matrix(y_dev,y_pred_svm))\n",
    "print(classification_report(y_dev,y_pred_svm))\n",
    "print(accuracy_score(y_dev, y_pred_svm)\n",
    "with open('svm.txt', 'w') as wf:\n",
    "    for item in y_pred_svm:\n",
    "        wf.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eventually, results need to be a list of 2028 0 or 1's\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Prediction Result File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to submit a prediction result file. It should have 2028 lines, every line should be either 0 or 1, which is your model's prediction on the respective test set instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose you had your model's predictions on the 2028 test cases read from test_enc_unlabeled.tsv, and \n",
    "#those results are in the list called 'results'\n",
    "assert (len(results) == 2028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the results are not float numbers, but intergers 0 and 1\n",
    "results = [int(x) for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your prediction results to 'upload_predictions.txt' and upload that later\n",
    "with open('upload_predictions.txt', 'w', encoding = 'utf-8') as fp:\n",
    "    for x in results:\n",
    "        fp.write(str(x) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python310064bitfb335e516cf1419fa40eefd43c9b328c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}